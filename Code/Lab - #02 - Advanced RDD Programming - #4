# Spark Web UI의 Stage 메뉴에서 task 개수를 참고하여 파티션 수 확인 -> 총 파일 수 : 1.6 MB 파일 1개  --> RDD 파티션 2개
ordersRdd1=sc.textFile('wasbs://ghtestbigdata@ghtestdatastacc.blob.core.windows.net/sparkhol/rdd-partition-data/ordersTbls/small-01/orders.tbl').map(lambda line: line.split("|")) 
ordersRdd1.getNumPartitions()

ordersRdd1.count()

# Spark Web UI의 Stage 메뉴에서 task 개수를 참고하여 파티션 수 확인 -> 총 파일 수 : 1.6 MB 파일 2개  --> RDD 파티션 2개
ordersRdd2=sc.textFile('wasbs://ghtestbigdata@ghtestdatastacc.blob.core.windows.net/sparkhol/rdd-partition-data/ordersTbls/small-[01-02]/orders.tbl').map(lambda line: line.split("|")) 
ordersRdd2.getNumPartitions()

ordersRdd2.count()

# Spark Web UI의 Stage 메뉴에서 task 개수를 참고하여 파티션 수 확인 -> 총 파일 수 : 1.6 MB 파일 3개  --> RDD 파티션 3개
ordersRdd3=sc.textFile('wasbs://ghtestbigdata@ghtestdatastacc.blob.core.windows.net/sparkhol/rdd-partition-data/ordersTbls/small-[01-03]/orders.tbl').map(lambda line: line.split("|")) 
ordersRdd3.getNumPartitions()

ordersRdd3.count()

# Spark Web UI의 Stage 메뉴에서 task 개수를 참고하여 파티션 수 확인 -> 총 파일 수 : 1.6 MB 파일 7개 & 164 MB 1개 --> RDD 파티션 9개
ordersRdd4=sc.textFile('wasbs://ghtestbigdata@ghtestdatastacc.blob.core.windows.net/sparkhol/rdd-partition-data/ordersTbls/*/orders.tbl').map(lambda line: line.split("|")) 
ordersRdd4.getNumPartitions()

ordersRdd4.count()

# Spark Web UI의 Storage 메뉴에서 파티션 수 확인 -> 총 파일 수 : 1.6 MB 파일 7개 & 164 MB 1개 --> RDD 파티션 9개
ordersRdd4.cache()
ordersRdd4.count()
